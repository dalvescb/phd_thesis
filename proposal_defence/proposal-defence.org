* Header :ignore:
# -*- mode: org; -*-

#+REVEAL_ROOT: https://cdn.jsdelivr.net/reveal.js/3.0.0/
# #+REVEAL_ROOT: /home/dalvescb/reveal.js/
# #+REVEAL_THEME: league
#+REVEAL_THEME: sky

#+OPTIONS: reveal_title_slide:auto num:nil toc:nil timestamp:nil

#+MACRO: color @@html:<font color="$1">$2</font>@@
#+MACRO: alert @@html:<font color="navy">$1</font>@@
#+MACRO: small @@html:<h3><font color="navy">$1</font></h3>@@
#+MACRO: smaller @@html:<h4>$1</h4>@@

#+REVEAL_PLUGINS: (highlight)

# #+REVEAL_EXTRA_CSS: ./mystyle.css
# #+REVEAL_EXTRA_CSS: /Users/curtis/reveal.js/css/theme/night.css

# To load Org-reveal, type “M-x load-library”, then type “ox-reveal”.


#+Title: {{{small(Analysis of Compiler Heuristics via Stochastic Scheduling and Hyper-Heuristics)}}}  
# Stochastic Optimization for Instruction Scheduling and Their Potential for Architecture Analysis 
#+Date: {{{smaller(2019-12-23)}}}
#+Email: curtis.dalves@gmail.com
#+Author: {{{smaller(A Thesis Proposal by Curtis D'Alves)}}}

#+REVEAL_TITLE_SLIDE_TEMPLATE:"<h6>%t<\h6>"

* Background
** Instruction Scheduling
  - {{{alert(Problem:)}}} 
    Given a set of instructions and dependencies, designate an order 
    (find a *schedule*) satisfying the dependencies and optimizing performance
  - Known {{{alert(NP-Complete Problem:)}}} practically solved by either
    - *Heuristics* (most commonly)
    - *Approximation Algorithms*
  - Compiler Heuristics {{{alert(need to evolve with their target
    architectures)}}}, making it a constantly ongoing problem in the field of
    compiler development

** Example: Instruction Dependency DAG
   #+CAPTION: IBM MASS Library COS DAG on Z14 Architecture
   #+ATTR_HTML: :width 110% :height 110%
   [[file:../figures/DAG.svg]]

** Instruction Level Parallelism (Pipelining)  
   Instruction execution can be broken into stages, the following pipeline uses four stages
    - {{{alert(IF = Instruction Fetch)}}}
    - {{{alert(ID = Instruction Decode)}}}
    - {{{alert(EX = Execute)}}}
    - {{{alert(MEM = Memory Access)}}}
    - {{{alert(WB =  Write Back)}}}
   #+CAPTION: Example Simple RISC Pipeline 
   #+ATTR_HTML: :width 95% :height 95%
   [[file:../figures/RISCPipeline.png]]

** Instruction Level Parallelism (SuperScalar Architectures)  
   Superscalar Architectures exploit {{{alert(Parallel Functional Units)}}} to
   execute multiple functions at once
   #+CAPTION: Example SuperScalar Pipeline 
   #+ATTR_HTML: :width 95% :height 95%
   [[file:../figures/SuperScalarPipeline.png]]

** Architecture Hazards
   - {{{alert(Data Hazards)}}} occur when a data dependency is broken. There are 3 types:
\begin{align*}
\qquad & \qquad & \\
\textbf{RAW}                    & \qquad & \textbf{WAR}                   \\ 
\textbf{R2} \leftarrow R5 + R3  & \qquad & R4 \leftarrow R1 + \textbf{R5} \\ 
R4 \leftarrow \textbf{R2} + R3  & \qquad & \textbf{R5} \leftarrow R1 + R2 \\ 
\textbf{WAW} & & \\
\textbf{R2} \leftarrow R4 + R7 & & \\
\textbf{R2} \leftarrow R1 + R3 & & 
\end{align*}
     - {{{alert(Structural Hazards)}}} occurs when an aspect of hardware is accessed at the
       same time (such as a functional unit)
     - {{{alert(Control Hazards)}}} occur when a bad branch
       prediction is made
      
** Pipeline Stalls  
  When a {{{alert(Hazard)}}} occurs, a {{{alert(No Operation (NOOP))}}} must be
  inserted, effectively {{{alert(Stalling the Pipeline)}}}
  
   #+CAPTION: Example of a bubble (NOOP) being inserted to fix an unfullfilled data dependency
   #+ATTR_HTML: :width 95% :height 95%
   [[file:../figures/PipelineStall.png]]
  
** Types Of Instruction Scheduling
   A scheduler attempts to {{{alert(maximize throughput)}}} (by avoiding
   pipeline stalls). The following different types of scheduling are worth
   noting:
   
   - {{{alert(Basic Block:)}}} (local acyclic) break code into blocks within branches (most commonly performed scheduling)
	 - {{{alert(Global Scheduling:)}}} (global cyclic) schedule across basic block boundaries
	 - {{{alert(Modulo Scheduling:)}}} (local cyclic) schedules basic blocks inside of a loop, seeking to
     optimize by interleaving iterations
	 - {{{alert(Trace Scheduling:)}}} (global acyclic/cyclic) tries to optimize control flow by predicting routes
     taken on branches

** Register Allocation
   - CPU's have a {{{alert(limited number of registers)}}} that must be
     allocated (generally after scheduling)
   - The problem of Register Allocation has been shown to be equivalent to that
     of {{{alert(Graph Coloring)}}}
     
   #+CAPTION: Register Allocation via Graph Coloring
   #+ATTR_HTML: :width 95% :height 95%
   [[file:../figures/GraphColor.png]]
  
** Spilling 
   When {{{alert(Register Allocation fails)}}}, a {{{alert(spill must be
   inserted)}}}
   - Choose a value {{{alert(v)}}} to spill to some address {{{alert(a)}}}
   - After the operation defining {{{alert(v)}}}, insert
     \begin{align*}
     \operatorname{store}(\operatorname{v}, \operatorname{a})
     \end{align*}
   - Before each operation that uses {{{alert(v)}}}, insert
    \begin{align*}
    v \leftarrow \operatorname{load}(\operatorname{a})    
    \end{align*}
   Generally has a {{{alert(large performance deficit)}}}. A {{{alert(good
   schedular)}}} should consider register allocation to {{{alert(avoid
   spilling)}}}
  
** In-Order vs Out-Of-Order Execution
  | {{{alert(Step)}}} | {{{alert(In-Order)}}}                    | {{{alert(Out-Of-Order)}}}                                    |
  |                1. | Instruction fetch                        | Instruction fetch                                            |
  |                2. | Stall until all operands are available   | Dispatch to a temporary queue known as *Reservation Station* |
  |                3. | Dispatch to appropriate functional unit  | Wait in the reservation station until operands are available |
  |                4. | Execute (on appropriate functional unit) | Issue once operands are available                            |
  |                5. | Write back to register file              | Execute (on appropriate functional unit)                     |
  |                6. |                                          | Retire results to another temporary queue                    |
  |                7. |                                          | Write results back to register files                         |
                                               
** Out-Of-Order Execution 
 Used in most modern architectures, {{{alert(increases potential for ILP)}}} but
 further complicates scheduling considerations 
 
   #+CAPTION: Out-Of-Order Execution Control Flow
   #+ATTR_HTML: :width 80% :height 80%
   [[file:../figures/OoODiagram.png]]

* Motivation 
** Motivation For Performance Oriented Scheduling
   - {{{alert(Conventional Heuristics)}}} used in compilers are suitable for
     finding near-optimal schedule for most code with moderate ILP available
   - The {{{alert(more potential ILP the more inadequate)}}} conventional
     compiler heuristics are
   - These heuristics {{{alert(favor compile time efficiency)}}}
   - {{{alert(Linked Libraries)}}} present an opportunity to schedule basic
     blocks ahead of time
   - Example: {{{alert(IBM MASS Libaries)}}} contain many important math
     functions that should be scheduled for near-optimal performance 
     
** Motivation For Schedule Space/Heuristic Analysis
   - Architectures are becoming {{{alert(increasing complicated)}}}
   - Design decisions are sometimes made by fad (i.e favoring micro-benchmarks
     for applications such as ML functions like sigmoid)
   - Heuristic relevance {{{alert(need to be re-evaluated)}}} as
     architectures are updated
   - {{{alert(Developing Heuristics)}}} is difficult and costly (requires a lot
     of man power)
     
* Current State of the Art and Notable/Relevant Works in Instruction Scheduling

** List Scheduling 
#+BEGIN_SRC ada
while there are instrs to be scheduled do 
      Identify highest priority instr n
      Choose a processor p for n
      Schedule n on p at est(n,p)
end

est(n,p) = earliest start time of n on p
#+END_SRC
   - {{{alert(Most commonly performed scheduling)}}}, used in some form by
     conventional compiler
   - {{{alert(Greedy Algorithm)}}}, schedules by {{{alert(priorities assigned by
     heuristics)}}}

** Instruction Scheduling using Constraint Programming
   - Abid Malik, Jim McInnes, Peter van Beek
   - Used {{{alert(Constraint Programming)}}} to optimize over a given DAG $G =
     (N,E)$ with the following constraints:
     - *Latency Constraints*, i.e
       - Given a labeled dependency DAG $G = (N,E)$ 
          - $\forall (i,j) \in E \cdot j \geq i + l(i,j)$ 
     - *Resource Constraints* that ensured functional units were not exceeded
     - *Distance Constraints*, i.e
       - Given a labeled dependency *DAG*  $G = (N,E)$ 
         - $\forall (i,j) \in E \cdot j \geq i + d(i,j)$
    
** Stochastic Search 
   - Schkufza, Sharma, Aiken at Stanford
   - Uses a {{{alert(Multi-Pass Stochastic Algorithm)}}} to {{{alert(iteratively
     transform basic block schedules)}}} by minimizing the following cost function

  \begin{align*}
    \qquad \\
    \operatorname{cost}(R; T) = w_e \times \operatorname{eq}(R; T) + w_p \times \operatorname{perf}(R; T) \\
    \qquad 
  \end{align*}

  | $\color{darkblue}{\boldsymbol{R}}$             | any rewrite of the program                                      |
  | $\color{darkblue}{\boldsymbol{T}}$             | the input program sequence                                      |
  | $\color{darkblue}{\operatorname{eq}(\cdot)}$   | the equivalence function (0 if $\color{darkblue}{R \equiv T}$ ) |
  | $\color{darkblue}{\operatorname{perf}(\cdot)}$ | a metric for performance                                        |
  | $\color{darkblue}{\boldsymbol{w_e}}$           | weight for the equivalence term                                 |
  | $\color{darkblue}{\boldsymbol{w_p}}$           | weight for the performance term                                 |

 - Uses {{{alert(Markov-Chain-Monte-Carlo (MCMC))}}} sampling to stochastically
   explore schedule space

* Research Efforts Thus Far
** Focus on Finding Near-Optimal Schedules for MASS Libraries
   - scheduling inside a loop ({{{alert(modulo scheduling)}}})
   - ignoring {{{alert(global/trace)}}} scheduling techniques
   - scheduling on {{{alert(IBM Z)}}} (hopefully {{{alert(POWER)}}} coming soon) 
   - little consideration for cost of schedule generation
   - Up to 20% speedup on core functions already achieved

** Continuous Optimization Model For Modulo Scheduling
#+BEGIN_cmath
#+HTML: <small>
\begin{align}
    \color{navy}{\text{Objective Variables }} & t_i, b_i, f_i:& \mathbb{R} \\
    \color{navy}{\text{Constants }} & \textrm{II} :& \mathbb{R} \\
    \color{navy}{\text{Indicator Function }} & \mathbb{IN} :& \mathbb{R} \rightarrow \mathbb{R} \\
    & t_i :& \text{dispatch time} \\
    & b_i :& \text{completion time} \\
    & f_i :& \text{FIFO use } 0 \leq f_i \leq 1 \\
    & \textrm{II} :& \text{iteration interval} \frac{\# instructions}{dispatches/cycle} \\
\end{align}
#+HTML: </small>
#+END_cmath

  {{{alert(NOTE)}}}: dispatch and completion times are designed to model *OoO* (Out of Order) execution machines 
  
** Continuous Optimization Model
#+BEGIN_cmath
#+HTML: <small>
\begin{align}
    \color{navy}{\text{Hard Constraints }} \qquad & \forall i,j \cdot i \rightarrow j \qquad t_i + \epsilon \leq t_j  \\
								 & 0 \leq t_i \leq b_i \leq \#\text{stages} \cdot \textrm{II}  \\
								 & b_i + \epsilon \leq t_i + \textrm{II} \\
    \color{navy}{\text{Objective Function }} \qquad   & \text{min} \sum_{i} (b_i - t_i + f_i) + \text{Penalties}
\end{align}
#+HTML: </small>    
#+END_cmath

{{{alert(Key Idea:)}}} Encode choice heuristics as penalties, adjust preference
between heuristics by scaling

** IO Penalty
   - {{{alert(IDEA)}}} penalize dispatch time of instructions based on the quantity and
    latencies of it's dependencies
   - {{{alert(Note)}}} This is a *penalty* not a *hard* constraint on latencies

#+BEGIN_cmath
#+HTML: <small>
   \begin{align*}
            \color{navy}{\text{Given }} \qquad  & t_i,t_j \qquad & \forall i,j \mid i \rightarrow j  \\
            \color{navy}{\text{For each i }} \qquad & N_j  =  \sum_{i \rightarrow j} \text{latency}(j) & \\
            \qquad & \qquad & \qquad \\
            \qquad & \mathbb{IO}(i) = \sum_{j} \frac{1}{N_j} \mathbb{IN}(t_i - t_j) & \qquad 
    \end{align*}
#+HTML: </small>
#+END_cmath

** Indicator Function (Custom Sigmoid)
   #+ATTR_HTML: :width 70% :height 70%
   [[file:../figures/sigmoid.jpg]]

    \[ S(x) = \frac{1}{(1 + e^{s(-0.5 + v)})(1 + e^{s(-0.5-v)})} \]
    
** Stochastic Scaling
   - The scaling $\color{black}{\frac{1}{N_j}}$ may be a good *guess*, but not necessarily effective in practice
   - {{{alert(IDEA)}}} scale the {{{alert(IO penalty)}}} stochastically
#+BEGIN_cmath
#+HTML: <small>
      \begin{align*}
          \color{navy}{\text{Define a Grouping}} \qquad & \mathbb{C} = \text{Group}(\forall i \mid i \rightarrow j) \\
          \color{navy}{\text{For each Group i}} \qquad & c_i \in \mathbb{RAND(R)} \\
          \color{navy}{\text{Stochastic Penalty}} \qquad & \sum_i c_i \cdot \mathbb{IO}(i)
        \end{align*}
#+HTML: </small>
#+END_cmath

** Forming Heuristics as Penalties
   Different categories of heuristics can be formed by 
    - {{{alert(Grouping)}}} different types of instructions
    - using the right {{{alert(Indicator Function)}}}

* What do we gain from this approach?
  - {{{alert(Continuous Optimization)}}} algorithm provides a flexible space for schedules to span
    - Different heuristics can be encoded as penalties, scaled for priority
  - {{{alert(Stochastic)}}} element provides a means to generate a variety of
    schedules (i.e generate datasets)

* Proposed research    

** Hyper-Heuristics For Instruction Scheduling
   - {{{alert(Meta-Optimization)}}} is the use of one optimization method to
     tune another
   - {{{alert(Hyper-heuristics)}}} are an offspring of meta-optimization, that
     focuses on {{{alert(learning the space of heuristics)}}} 
   - The set of {{{alert(penalty scalings)}}} from encoding heuristics as
     penalties provides a {{{alert(heuristic space to learn)}}} 
   - Various ML techniques should be explored, in particular:
     - {{{alert(Genetic Programming)}}}
     - {{{alert(Support-Vector Machines (SVM))}}}
       
** Heuristic Analysis
  - By developing hyper-heuristics {{{alert(on a variety of architectures)}}}
    (i.e IBM Z, POWER, .... possibly ARM) and in-between versions of each
    architecture may {{{alert(show contrast between heuristic effectiveness per
    architecture design features)}}}
  - {{{alert(Principal Component Analysis (PCA))}}} is a mathematical technique
    for {{{alert(dimensionality reduction)}}} used in conjunction with ML techniques
  - Possibly {{{alert(use PCA)}}} and other statistical correlation analysis
    techniques to {{{alert(analyze heuristic effectiveness)}}}

** Evaluation of Methods   
  - Performance oriented schedules for MASS libraries generated with our
    stochastic algorithm are
    {{{alert(evaluated for speedup against previous iterations)}}} of the libraries 
  - Evaluation of {{{alert(hyper-heuristic)}}} methods will performed by
    comparing against current {{{alert(IBM XL C Compiler Heuristics)}}}
  - {{{alert(Qualitative analysis)}}} of architecture design feature's influence
    on common heuristics should be performed

* Overview / Conclusions 
  - My proposal is to {{{alert(explore the use of hyper-heuristics for
    instruction scheduling)}}} by learning parameters from my continuous
    optimization model
  - This is an ambitious project requiring the use of methods spanning a wide
    range of fields, including 
    - compiler development
    - computer architecture design
    - continuous optimization
    - machine learning
  - If successful, this research could have a {{{alert(large impact on compiler
    and computer architecture design)}}} process in industry
    
* RoadMap
   - Construct optimization model that can *encode heuristics* as penalties {{{color(green,CHECK)}}}
   - Verify we can use *stochastic scaling* to span a variety of schedules {{{color(green,CHECK)}}}
   - Verify we can use model to find *near-optimal* schedules {{{color(green,CHECK)}}}
   - *Generate data sets* for various architectures and heuristics {{{color(red,TBA)}}}
   - Experiment with ML techniques for developing *hyper-heuristic* methods {{{color(red,TBA)}}}
   - Utilize *data analysis* to rate effectiveness of different heuristics on different architectures {{{color(red,TBA)}}}

* Questions?
