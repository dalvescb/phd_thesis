* Header :ignore:
# -*- mode: org; -*-

#+REVEAL_ROOT: https://cdn.jsdelivr.net/reveal.js/3.0.0/



#+REVEAL_ROOT: https://cdn.jsdelivr.net/npm/reveal.js@3.9.0
#+REVEAL_VERSION: 3.9.0
#+REVEAL_THEME: sky

#+OPTIONS: reveal_title_slide:auto num:nil toc:nil timestamp:nil

#+MACRO: color @@html:<font color="$1">$2</font>@@
#+MACRO: alert @@html:<font color="navy">$1</font>@@
#+MACRO: small @@html:<h3><font color="navy">$1</font></h3>@@
#+MACRO: smaller @@html:<h4>$1</h4>@@

# #+REVEAL_EXTRA_CSS: ./mystyle.css
# #+REVEAL_EXTRA_CSS: /Users/curtis/reveal.js/css/theme/night.css

# To load Org-reveal, type “M-x load-library”, then type “ox-reveal”.


#+Title: {{{small(Coconut: A Rapid Prototyping Environment for Compiler Optimization)}}}  
# Stochastic Optimization for Instruction Scheduling and Their Potential for Architecture Analysis 
#+Date: {{{smaller(2022-08-24)}}}
#+Email: curtis.dalves@gmail.com
#+Author: {{{smaller(Curtis D'Alves)}}}

#+REVEAL_TITLE_SLIDE_TEMPLATE:"<h6>%t<\h6>"

* Background
** Who Am I?
   - {{{alert(Ph.D Candidate)}}} McMaster University
   - Did my Master's in {{{alert(Continuous Optimization Algorithms)}}}
   - Working on {{{alert(CAS Project 1006)}}}
   - Functional Programming / NixOS / Emacs enthusiast

** CAS Project 1006
   {{{alert(Stochastic Algorithms for Instructions Scheduling)}}}
   Emphasis on:
     - finding near-optimal schedules for performance critical code
     - modulo scheduling for loop bodies
     - Out-of-order architectures
     - The Z/OS IBM MASS libraries
   
** Previous Work: Kriston Costa
   - Utilized modified version of {{{alert(Kargers Min Cut Algorithm)}}}
   - {{{alert(Approximation Algorithm)}}} that can be performed {{{alert(stochastically)}}}
   - Takes successive *min-cuts* across a graph (dependency graph will {{{alert(minimize register pressure)}}})

** Karger's Minimum Cut Algorithm     
   [[file:kargermincut.png]]
   Cuts create {{{alert(groups)}}} that are candidates to {{{alert(interleave across stages)}}} in *modulo scheduling*

** My Work
   {{{alert(Continuous Optimization Model For Modulo Scheduling)}}}
#+BEGIN_cmath
#+HTML: <small>
\begin{align*}
    \color{navy}{\text{Objective Variables }} & t_i, c_i, s_i:& \mathbb{R} \\
    \color{navy}{\text{Constants }} & \textrm{II} :& \mathbb{R} \\
    \color{navy}{\text{Indicator Function }} & \mathbb{IN} :& \mathbb{R} \rightarrow \mathbb{R} \\
    & t_i :& \text{dispatch time} \\
    & c_i :& \text{completion time} \\
    & s_i :& \text{SPILL candidacy } 0 \leq s_i \leq 1 \\
    & \textrm{II} :& \text{initiation interval} \frac{\# instructions}{dispatches/cycle} \\
\end{align*}
#+HTML: </small>
#+END_cmath

  {{{alert(NOTE)}}}: dispatch and completion times are designed to model *OoO* (Out of Order) execution machines 
  
** Constrained Optimization Model
#+BEGIN_cmath
#+HTML: <small>
\begin{align}
    \color{navy}{\text{Hard Constraints }} \qquad & \forall i,j \cdot i \rightarrow j \qquad t_i + \epsilon \leq t_j  \\
								 & 0 \leq t_i \leq c_i \leq \#\text{stages} \cdot \textrm{II}  \\
								 & c_i + \epsilon \leq t_i + \textrm{II} \\
    \color{navy}{\text{Objective Function }} \qquad   & \text{min} \sum_{i} (c_i - t_i) + \text{Penalties}
\end{align}
#+HTML: </small>    
#+END_cmath

{{{alert(Key Idea:)}}} Encode choice heuristics as penalties, adjust preference
between heuristics by scaling

** Lifetime Penalty
   - {{{alert(IDEA)}}} penalize the overall lifetime of an instruction
   - {{{alert(Note)}}} This is a *penalty* not a *hard* constraint on latencies

     #TODO change IO penalty to lifetime penalty  (also consider labeling
     variables)
#+BEGIN_cmath
#+HTML: <small>
   \begin{align*}
            \color{navy}{\text{Given }} \qquad  & t_i,t_j \qquad & \forall i,j \mid i \rightarrow j  \\
            \color{navy}{\text{For each i }} \qquad & N_j  =  \sum_{i \rightarrow j} \text{latency}(j) & \\
            \qquad & \qquad & \qquad \\
            \qquad & \mathbb{IO}(i) = \sum_{j} \frac{1}{N_j} \mathbb{IN}(t_i - t_j) & \qquad 
    \end{align*
#+HTML: </small>
#+END_cmath
    
** Stochastic Scaling
   {{{alert(IDEA)}}} use random variables to scale penalties
#+BEGIN_cmath
#+HTML: <small>
      \begin{align*}
          \color{navy}{\text{Define a Grouping}} \qquad & \mathbb{C} = \text{Group}(\forall i \mid i \rightarrow j) \\
          \color{navy}{\text{For each Group i}} \qquad & X_i \in \mathbb{RAND(R)} \\
          \color{navy}{\text{Stochastic Penalty}} \qquad & \sum X_i \cdot \mathbb{P}(i)
        \end{align*}
#+HTML: </small>
#+END_cmath

* Rapid Prototyping With COCONUT   
** Rapid Prototyping With COCONUT 
   {{{alert(COCONUT)}}}:( {{{alert(CO)}}}ode {{{alert(CON)}}}structing {{{alert(U)}}}ser {{{alert(T)}}}ool )

   - An {{{alert(Interactive Development ToolSet)}}} for performance critical assembly code,
     #+BEGIN_SRC mermaid :file coconut.png
      graph TD
        A[DSL] -->|Language Instance| B[Interpreter]
        A -->|Language Instance| C[CodeGraph]
        C --> D[Scheduler]
        D --> C
        C --> E[Simulator]
        C -->|Printer| F[AssemblyCode]   
     #+END_SRC

     #+ATTR_HTML: :width 70% :height 50%
     #+RESULTS:
     [[file:coconut.png]]

**  Coconut Domain Specific Language (DSL)
   - Performance critical assembly code can be encoded in the Coconut {{{alert(eDSL)}}} 
   - {{{alert(Example COCONUT CODE)}}}
   #+BEGIN_SRC haskell
   class CoreISA r where
       unintegerG :: Integer -> r GPR
       unintegerV :: Integer -> r VR
       add :: r GPR -> r GPR -> r GPR
       mult :: r GPR -> r GPR -> r GPR
       vadd :: r VR -> v VR -> v VR
       ...
   #+END_SRC

** Coconut Example Basic Block
   #+BEGIN_SRC haskell
   testDSL :: CoreISA r =>
              r GPR -> r GPR -> (r GPR,r GPR)
   testDSL r1 r2 r3 =
     let
       r4 = add r2 r1
       r5 = add r3 r1
       r6 = add r4 r5
     in (r5,r6)
   #+END_SRC
   We can encode basic blocks in the Coconut DSL

** One Piece of Code, alot of Functionality
   - Type Safety
   - Single Static Assignment
   - Code generation
   - Interpretation
   - Simulation
     
** Hashed Expression Optimization DSL
  #+BEGIN_SRC haskell :results value
  topBottomPenalty :: Hardware h
    => Double
    -> HashedData h
    -> [TypedExpr Scalar R]
  topBottomPenalty scale hashedData =
    let
      instructions = hdAllInstructions hashedData
      tVars = tVarMap hashedData
      cVars = cVarMap hashedData
    in map (\n -> scale * (cVars ! n - tVars ! n)) instructions
  #+END_SRC
   We can easily encode our Lifetime Penalty from before

** Control Flow DSL
#+REVEAL_HTML: <div class="column" style="float:left; width: 50%">
   #+BEGIN_SRC mermaid :file controlflow.png
   graph TD
    A[a0] -->|DataFlowA| B[a1]
    B -->|BranchEQ| C[b0]
    B -->|BranchNE| D[c0]
    C -->|DataFlowB| E[b1]    
    D -->|DataFlowC| F[c1]    
    F -->|Jump| A    
   #+END_SRC
   
   #+RESULTS:
   [[file:controlflow.png]]
#+REVEAL_HTML: </div>

#+REVEAL_HTML: <div class="column" style="float:right; width: 50%">
#+BEGIN_SRC haskell :results value
testCFG dfA dfB dfC =
 do blockA <- genBlock $ dfA
    blockB <- genBlock $ dfB
    blockC <- genBlock $ dfC
    branchCFN (cfOut blockA)
              (cfIn blockB)
              (cfIn blockC)
    jumpCFN (cfOut blockC)
            (cfIn blockA)
#+END_SRC
#+REVEAL_HTML: </div> 

** COCONUT Features
     - Provides {{{alert(Code Graph Library)}}} for modeling dependency *DAG* 
     - Provides {{{alert(Register Allocator)}}} 
     - Provides {{{alert(Hardware Simulator)}}} 
     - Provides {{{alert(Code Generation)}}}

* Functional Graph Composition
  #+BEGIN_SRC haskell :results value
  data DataFlowGraph h =
    DataFlowGraph { -- the underlying functional graph structure
                    dataFlowGraph :: Gr (DFNode h) DFEdge
                    -- inputs nodes with tags
                  , dataFlowInputs :: [(String,Node)]
                    -- output nodes with tags
                  , dataFlowOutputs :: [(String,Node)]
                    -- the stage used for modulo scheduling
                  , dataFlowStage :: Int
                  ...
                  }
  
  #+END_SRC
  Basic blocks are encoded as Data Flow Graphs with tagged inputs/outputs

** Data Flow Graph Operations
  #+BEGIN_SRC haskell :results value
  --  partition a graph by a given predicate
  partGraphByInstr :: forall h . Hardware h =>
   (DataFlowGraph h) -> (Node -> Bool) -> (DataFlowGraph h,DataFlowGraph h)
  
  -- unpartition a graph (by tying togeether input/output node tags) 
  unPartDFGraph :: forall h . Hardware h =>
    DataFlowGraph h -> DataFlowGraph h -> DataFlowGraph h
    
  -- merge graphs in parallel
  parallelMergeDFGraph :: forall h . Hardware h =>
    (DataFlowGraph h,DataFlowGraph h) -> DataFlowGraph h
  #+END_SRC 
  Coconut provides useful combinators for deconstructing and reconstructing data
  flow graphs

** Software Pipelining Case Study
  #+REVEAL_HTML: <div class="column" style="float:left; width: 50%">
  #+BEGIN_SRC python
  for i in range(0,n):
      S0[i]
      S1[i]
      S2[i]
  #+END_SRC
  {{{alert(Sample loop body)}}}
  #+REVEAL_HTML: </div>
  
  #+REVEAL_HTML: <div class="column" style="float:right; width: 50%">
  #+BEGIN_SRC python
  for i in range(0,n-2):
       -- Kernel
      S0[i+2] ; S1[i+1] ; S2[i]
  #+END_SRC
  {{{alert(Modulo Scheduled loop body)}}}
  #+REVEAL_HTML: </div>  

** Software Pipelining Case Study
   - Partition the dataflow graph by stage using *partNGraphByInstr*
     #+BEGIN_SRC haskell :results value
     numStages   :: Int
     withinStage :: Int -> Node -> Bool
     ...
     partDFGraphs :: [DataFlowGraph h]
     partDFGraphs = partNGraphByInstr dfGraph withinStage numStages
     #+END_SRC
   - Apply transformations to each partition and then pipeline using *parallelMergeGraphs*
    #+BEGIN_SRC haskell :results value
    kerenelParts :: [DataFlowGraph h]
    kernelParts = map applyIncrement (zip [0..] partDFGraphs )

    kernel :: DataFlowGraph
    kernel = parallelMergeDFGraphs kernelParts
    #+END_SRC

** Control Flow Graph Composition   
    Given a dataflow graphs with tagged inputs/outputs
   #+REVEAL_HTML: <div class="column" style="float:left; width: 50%">
     #+BEGIN_SRC haskell :results value
    dfGraph0 = DataFlowGraph {
      fglGraph = ....
      ,dataFlowInputs =
        [("x:0",0)("y:0",1)]
      ,dataFlowOutputs =
        [("x:0",2)("z:0",3)]
      ,dataFlowStage = 0
      }
     #+END_SRC
   #+REVEAL_HTML: </div>
   
   #+REVEAL_HTML: <div class="column" style="float:right; width: 50%">
     #+BEGIN_SRC haskell :results value
    dfGraph1 = DataFlowGraph {
        fglGraph = ....
        ,dataFlowInputs =
          [("x:1",4)("z:1",5)]
        ,dataFlowOutputs =
          [("x:1",5)]
        ,dataFlowStage = 1
        }
     #+END_SRC
   #+REVEAL_HTML: </div>  
   Compose Graph in Control Flow
   #+BEGIN_SRC haskell :results value
   compose dfGraph0 dfGraph1 =
     do blockA <- genBlock $ dfGraph0
        blockB <- genBlock $ dfGraph1
        jumpCompose (\i -> i+1 `mod` numStages)
                    (cfOut blockA)
                    (cfIn blockB)
   #+END_SRC
* Questions? 
  
  

#  LocalWords:  CAS
