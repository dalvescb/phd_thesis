#+TITLE: Thesis Proposal Title
#+DESCRIPTION: Thesis proposal for Curtis D'Alves; McMaster University 2019.
#+AUTHOR: [[mailto:dalvescb@mcmaster.ca][Curtis D'Alves]]
#+EMAIL: curtis.dalves@gmail.com
#+OPTIONS: toc:nil d:nil title:nil
#+PROPERTY: header-args :tangle no :comments link

# At the end of a section, explain why the section is there,
# and what the reader should take away from it.

# MA: LaTeX pads colons, :, with spacing.
# For inline typing annotations, use ghost colon “\:” to avoid this issue.

* Preamble & title page :ignore:

# Top level editorial comments.
#+MACRO: remark  @@latex: \fbox{\textbf{Comment: $1 }}@@

** Minted setup -- colouring code blocks                            :ignore:

#+LATEX_HEADER: \usepackage[]{minted}
#+LATEX_HEADER: \usepackage{tcolorbox}
#+LATEX_HEADER: \usepackage{etoolbox}
#+LATEX_HEADER: \def\mytitle{??? Program Code ???}
#+LATEX_HEADER: \BeforeBeginEnvironment{minted}{\begin{tcolorbox}[title=\hfill \mytitle]}%
#+LATEX_HEADER: \AfterEndEnvironment{minted}{\end{tcolorbox}}%

# Before a code block, write {{{code(title-of-block)}}}
#
#+MACRO: code     #+LaTeX: \def\mytitle{$1}

#+LaTeX: \setminted[haskell]{fontsize=\footnotesize}
#+LaTeX: \setminted[agda]{fontsize=\footnotesize}

# Removing the red box that appears in "minted" when using unicode.
# Src: https://tex.stackexchange.com/questions/343494/minted-red-box-around-greek-characters
#
#+LATEX_HEADER: \makeatletter
#+LATEX_HEADER: \AtBeginEnvironment{minted}{\dontdofcolorbox}
#+LATEX_HEADER: \def\dontdofcolorbox{\renewcommand\fcolorbox[4][]{##4}}
#+LATEX_HEADER: \makeatother
** LaTeX setup                                                      :ignore:

# Hijacking \date to add addtional text to the frontmatter of a ‘report’.
#
#
# DATE: \today\vfill \centerline{---Supervisors---} \newline [[mailto:carette@mcmaster.ca][Jacques Carette]] and [[mailto:kahl@cas.mcmaster.ca][Wolfram Kahl]]

#+LATEX_HEADER: \usepackage[hmargin=25mm,vmargin=25mm]{geometry}
#+LaTeX_HEADER: \setlength{\parskip}{1em}
#+latex_class_options: [12pt]
#+LATEX_CLASS: report-noparts
# Defined below.
#
# Double spacing:
# LaTeX: \setlength{\parskip}{3em}\renewcommand{\baselinestretch}{2.0}
#
#+LATEX_HEADER: \setlength{\parskip}{1em}

#+LATEX_HEADER: \usepackage[backend=biber,style=alphabetic]{biblatex}
#+LATEX_HEADER: \addbibresource{References.bib}

#+LATEX_HEADER: \usepackage{MyUnicodeSymbols}

#+LATEX_HEADER: \usepackage[dvipsnames]{xcolor} % named colours
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \definecolor{darkred}{rgb}{0.3, 0.0, 0.0}
#+LATEX_HEADER: \definecolor{darkgreen}{rgb}{0.0, 0.3, 0.1}
#+LATEX_HEADER: \definecolor{darkblue}{rgb}{0.0, 0.1, 0.3}
#+LATEX_HEADER: \definecolor{darkorange}{rgb}{1.0, 0.55, 0.0}
#+LATEX_HEADER: \definecolor{sienna}{rgb}{0.53, 0.18, 0.09}
#+LATEX_HEADER: \hypersetup{colorlinks,linkcolor=darkblue,citecolor=darkblue,urlcolor=darkgreen}

#+NAME: symbols for itemisation environment
#+BEGIN_EXPORT latex
\def\labelitemi{$\diamond$}
\def\labelitemii{$\circ$}
\def\labelitemiii{$\star$}

% Level 0                 Level 0
% + Level 1               ⋄ Level 1
%   - Level 2       --->      ∘ Level 2
%     * Level 3                   ⋆ Level 3
%
#+END_EXPORT

# Having small-font code blocks.
# LATEX_HEADER: \RequirePackage{fancyvrb}
# LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\scriptsize}

** ~reports-noparts~ LaTeX Class                                    :noexport:

A custom version of the reports class which makes the outermost headings chapters, rather than parts.
#+NAME: make-reports-class
#+BEGIN_SRC emacs-lisp :results none
(add-to-list
  'org-latex-classes
    '("report-noparts"
      "\\documentclass{report}"
      ("\\chapter{%s}" . "\\chapter*{%s}")
      ("\\section{%s}" . "\\section*{%s}")
      ("\\subsection{%s}" . "\\subsection*{%s}")
      ("\\subsubsection{%s}" . "\\subsubsection*{%s}")
      ("\\paragraph{%s}" . "\\paragraph*{%s}")
      ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
#+END_SRC

Source: Mark Armstrong --github ~armkeh~
** Personal title page                                              :ignore:

#+begin_center org

#+begin_export latex
\thispagestyle{empty}

{\color{white}{.}}

\vspace{5em}

{\Huge Thesis Proposal Title}

\vspace{1em}

{\Large Possibly some more bullshit here}

\vspace{2em}

Department of Computing and Software

McMaster University

\vspace{2em}
\href{mailto:curtis.dalves@gmail.com}{Curtis D'Alves}

\vspace{2em}
\today
#+end_export

\vfill

{{{code({\sc Thesis Proposal \hspace{12em} \color{grey}{.} })}}}
#+begin_src haskell
Christopher Anand                                    anandc@mcmaster.ca
Wolfram Kahl                                         kahl@cas.mcmaster.ca
#+end_src
#+end_center

# LaTeX: \centerline{\sc Draft}

* Abstract and toc                                                   :ignore:
:PROPERTIES:
:CUSTOM_ID: abstract
:END:

# Use:  x vs.{{{null}}} ys
# This informs LaTeX not to put the normal space necessary after a period.
#
#+MACRO: null  @@latex:\null{}@@

#+begin_abstract

In compiler optimization, *Instruction Scheduling* seeks to optimize the order of
a sequence of instructions to maximize throughput while preserving semantics.
As modern pipelined multi-core architectures become increasing more complex, with
techniques such as super-scaling, out of order execution, register remapping,
VLIW (Very Large Instruction Word) and
more scheduling software must itself become more sophisticated to fully
utilize this advanced hardware. However as a known NP-Complete problem, finding
the optimal schedule for a non-trivial program is too costly. Conventional
compilers opt to utilize heuristics that by default yield far from optimal schedules in
exchange for compile time performance. Tuning via compiler flags is complex
requiring expert insight (often the order of flags causes different heuristics
to overwrite one another) and is often ignored by developers. Statically/Dynamically
linked libraries present an opportunity to schedule pre-compiled binaries
outside of compile time making room to use more costly methods to find better
schedules for performance critical blocks.  

\vspace{1em}

This proposal explores techniques for scheduling performance critical code on
modern out-of-order architectures. Previous/Current techniques and their
relevance are detailed, including List Scheduling, Approximation Algorithms,
Stochastic Algorithms and (Non)Linear Programming. Of particular interest, the use of
stochastic algorithms presents opportunity to examine the space of feasible
schedules. We present a constrained non-linear optimization model that relaxes
the discrete nature of scheduling problems. By encoding heuristics as penalty
functions that can be scaled to assign priority and using stochastic-ally
generated scaling parameters we hope to examine the topology of valid schedules
in the more flexible space of $\textrm{R}^n$. 

\vspace{1em}

As a testing bed, we schedule the IBM\textsuperscript{\textregistered}
MASS\texttrademark (Math Acceleration Subsystem) library functions for the
Z\texttrademark and POWER\texttrademark architectures with already successful results,
finding schedules that outperform previous iterations of the library for select
functions.

#+begin_center org
#+begin_small
---Source: https://github.com/dalvescb/phd_thesis ---
#+end_small
#+end_center
#+end_abstract

\newpage
\thispagestyle{empty}
\tableofcontents
\newpage

* Introduction (Background)
  Given a set of instructions and dependencies, designate an order 
  (find a *schedule*) satisfying the dependencies and optimizing performance.
    Even simple formulations of optimal instruction scheduling is an NP compelte search problem \parencite{hennessy1983postpass} 
    As such, practical solutions to instruction scheduling problems are given by either:
    - *Heuristics*
    - *Approximation Algorithms*
  These algorithms take a model of the program (typically represented as a
  dependency DAG \parencite{gibbons1986efficient}) as input and return an
  ordering as output. 

*** TODO COMMENT finish introduction (background) heading
** Types of Instruction Scheduling
   \parencite{rau1993instruction} TODO REFERENCE HISTORY OF INSTRUCTION-LEVEL
   PARALLEL PROCESSING
   - *Basic Block:* break code into blocks within branches (most commonly performed scheduling)
	 - *Global Scheduling:* schedule across basic block boundaries
	 - *Modulo Scheduling:* schedules basic blocks inside of a loop, seeking to
     optimize by interleaving iterations
	 - *Trace Scheduling:* tries to optimize control flow by predicting routes
     taken on branches
*** TODO COMMENT update types of scheduling from beamer
** Register Allocation
   \parencite{Chaitin:1982:RAS:872726.806984} TODO REFERENCE REGISTER ALLOC
   - Given a schedule, assign registers keeping in mind
    - limited number of registers
    - can't rewrite a register until consumed by dependent instructions
   - Known NP-Complete
     - Practically solved using non-optimal *Graph Coloring* algorithms
     - done seperately from instruction scheduling (before or afterwords)
*** TODO COMMENT update register allocation from beamer
** Graph Coloring
   [[file:figures/nshape.png]]
   
   Find a *k-Colouring* for the dependency graph, where *$k = \#Registers$*
*** TODO COMMENT update graph coloring from beamer

** Spilling
   - What if a *k-Coloring* can't be found? Must *Spill* memory
	 - Simply insert new *Load / Store* instructions as needed
   - Potentially *creates new stalls* in the pipeline, need to re-perform
     scheduling
   - May use up dispatch slots
   - An *Ideal Schedule* has no spilling
*** TODO COMMENT update spilling from beamer

** Combining Register Allocation and Instruction Scheduling
   - Register Allocation is generally done after instruction scheduling
   - This can *make spilling necessary*
   - Register allocation can be performed before instruction schedule, but will
     *constrain the space of valid schedules*
   - Attempts to *combine register allocation and scheduling* are
     rare and yield an *NP-hard* problem \parencite{motwani1995combining} \parencite{Pinter:1993:RAI:173262.155114}
*** TODO COMMENT update combining register alloc from beamer
** Instruction Pipelining
     [[file:figures/pipeline.png]]
  
 Simple example pipeline with no stalls and a single instruction fetch per
 "cycle"
*** TODO COMMENT update instruction pipelining from beamer
** SuperScalar Architectures
   \parencite{bernstein1991global} USE REFERENCE ABOUT SUPERSCALAR PIPELINE SCHEDULING
   #+ATTR_LATEX: :width 0.5\textwidth
      [[file:figures/superscaler.png]]
   
   Superscalar architectures can fetch multiple instructions per "cycle" and
   require more thought about resource restriction (such as limits on ALU's)
*** TODO COMMENT update superscalar architectures from beamer
** Pipeline Stalls
   [[file:figures/bubbles.png]]
   [[file:figures/bubbles2.png]]
   
   An ideal shedule (like in the previous figures) contains *NO* stalls (often
   not possible)
*** TODO COMMENT update pipeline stalls from beamer
** Hazards
		- *Data Hazards*
			- read after write *RAW*
			- write after read *WAR*
			- write after write *WAW*
		- *Structural Hazards* occurs when an aspect of hardware is accessed at the same time
		- *Control Hazards* caused by branching, next instruction unknown
    Hardware encountering hazards causees stalls in the pipeline
*** TODO COMMENT update hazards from beamer
** Swing Modulo Scheduling: Staging
   #+ATTR_LATEX: :width 0.5\textwidth
   [[file:figures/staging.png]]

   When performing *modulo scheduling*, a basic block of a loop can be broken
   into stages and the loop can be *unrolled* to interleave stages between
   iterations
*** TODO COMMENT update staging from beamer
** Iteration Interval
\begin{equation}
  \frac{\text{latency height}}{\# \text{stages}} \leq \textrm{II}
\end{equation}
   - the maximum *number of cyles* to complete a loop iteration
   - exact number is complicated *Out of Order Execution* / *Staging*
*** TODO COMMENT update II from beamer
** Register Remapping
   When executing machine code, hardware maps *Logical Registers* to *Physical Registers*
   -  *Logical Registers* are a set of registers usable directly when
     writing/generating assembly code (limited by system architecture)
   - *Physical Registers* are a set of registers actually available in hardware
   Having a larger number of Physical registers than Logical registers gives
   hardware extra flexibility when dispatching instructions for *Out of Order Execution*
*** TODO COMMENT update register remapping from beamer
** Out-of-Order Execution
   #+BEGIN_SRC ditaa :file figures/OoODiagram.png
   /--------------\      /-------------\
   | Instr 0.     | ...  | Instr. n    |
   \--------------/      \-------------/
         |           |         |
   /--------------\      /-------------\
   | Fetcher 0.   | ...  | Fetcher n   |
   \--------------/      \-------------/
         |           |         |
         |           |         |
         \---------------------/
                     |
                     v
            /-----------------\
            | cBLU Grouper    |           Register Remapping
            \-----------------/
                     |
                     |
                     v 
            /-----------------\
            | cBLU Dispather  |
            \-----------------/
                     |
     -------------------------------------
     |      |                     |      |
   /----\ /----\               /----\ /----\
   |cRED| |cRED|     ....      |cRED| |cRED|    OoO Exection
   \----/ \----/               \----/ \----/
     |      |                     |      |
     -------------------------------------
                     |
                     v 
            /-----------------\
            | cBLU Retire     |           Register UnMapping
            \-----------------/
   #+END_SRC

   #+ATTR_LATEX: :width 0.5\textwidth
   #+RESULTS:
   [[file:figures/OoODiagram.png]]
*** TODO COMMENT update out-of-order execution from beamer
** Register Pressure In Staged Loops
   - Staging can *increase pipeline throughput* by enabling more instructions to
     be scheduled between high latency operations and subsequent use
   - However this also increases the number of *live instances of loop
     variables* and thus requires more registers to accommodate the schedule
   - To deal with the access number of registers required that may not be
     available, *Register Queuing* (what we term FIFO's) may be
     necessary
   - Existing works have explored schemes of register queuing such as
     *Modulo Variable Expansion* and *Rotating Register
     File* \parencite{tyson2001evaluating}
*** TODO COMMENT update register pressure from beamer
* Current/Previous Approaches
*** TODO COMMENT write intro to current/previous approaches
** List Scheduling (most commonly performed scheduling)
   	Simple heuristic.  Choose a prioritized topological order that
    - Respects the edges in the data-dependence graph (*topological*)
    - Heuristic choice among options, e.g pick first the node with the longest path extending from that node *prioritized*
    Most commonly used method for scheduling. Efficient but yields far less than
    optimal schedules.

    Issues with list scheduling include 
    - Many factors to consider when constructing a schedule (everything listed in this presentation and more!)    
    - Difficult (or more accurately impossible!) to consider all these aspects into a single choice heuristic        
    - Combinations of heuristics can be used, and multiple iterations performed,
      but each will usually undo the work of the other
*** TODO COMMENT update list scheduling from beamer
** Linear/Constraint Programming
     \parencite{malik2008optimal} Found provably optimal schedules for basic blocks using constraint
     programming, with the following types of constraints
   - *Latency Constraints*, i.e
     - Given a labeled dependency DAG $G = (N,E)$ 
       - $\forall (i,j) \in E \cdot j \geq i + l(i,j)$ 
   - *Resource Constraints* that ensured functinonal units were not exceded
   - *Distance Contstraints*, i.e
     - Given a labeled dependency *DAG*  $G = (N,E)$ 
        - $\forall (i,j) \in E \cdot j \geq i + d(i,j)$

   The hard constraints on latency would not account for *Register Remapping* in
   *Out Of Order Execution* that would be able to find more optimal schedules
   despite the fact that latencies in normal execution would create *pipeline stalls*
   {{{code({\sc Assembly Code Example \hspace{12em} \color{grey}{.} })}}}
   #+BEGIN_SRC haskell
   fma r3,r3,r4
   fma r2,r2,r4
   fma r1,r1,r4
   fma r0,r0,r4
   #+END_SRC
   On a system with only 5 registers and an instruction fma of large enough
   latency, the scheduler would push these instructions apart. However a machine
   could use register remapping to execute these instructions efficiently Out-of-Order
   making that constraint unnecessary.
*** TODO COMMENT fix linear/constraint programming from beamer
** Stochastic Search
   Work by stanford \parencite{Schkufza:2016:SPO:2886013.2863701}
  - Suitable for *Short Basic Block* assembly code sequences
  - Utilizes a multiple pass *Stochastic Algorithm*
  - Encodes constraints as a *Cost Function* and uses a
    *Markov Chain Monte Carlo Sampler* to explore space of all
    possible schedules

  Each pass of the optimization minimizes the cost function

  \begin{equation*}
    cost(R; T) = w_e \times eq(R; T) + w_p \times perf(R; T)
  \end{equation*}

  | $\color{lightgreen}{\boldsymbol{R}}$   | any rewrite of the program                                        |
  | $\color{lightgreen}{\boldsymbol{T}}$   | the input program sequence                                        |
  | $\color{lightgreen}{eq(\cdot)}$        | the equivalence function (0 if $\color{lightgreen}{R \equiv T}$ ) |
  | $\color{lightgreen}{perf(\cdot)}$      | a metric for performance                                          |
  | $\color{lightgreen}{\boldsymbol{w_e}}$ | weight for the equivalence term                                   |
  | $\color{lightgreen}{\boldsymbol{w_p}}$ | weight for the performance term                                   |

  Limitations with the approach as done by \parencite{Schkufza:2016:SPO:2886013.2863701} include
   - Only optimizes basic blocks (no loops)
   - Extremely innefficent (only practical for very short scheduling)
   - Performed in multiple passes with model checking
   - Cost function doesn't model the space of valid checking (hence model
     checking is required per each rewrite)
*** TODO COMMENT update stochastic search from beamer
* Proposed Approaches
** TODO COMMENT write intro to proposed approaches
** Optimization Model for Modulo Scheduling
\begin{align*}
    \color{lightblue}{\text{Objective Variables }} & t_i, b_i, f_i:& \mathbb{R} \\
    \color{lightblue}{\text{Constants }} & \textrm{II} :& \mathbb{R} \\
    \color{lightblue}{\text{Indicator Function }} & \mathbb{IN} :& \mathbb{R} \rightarrow \mathbb{R} \\
    & t_i :& \text{dispatch time} \\
    & b_i :& \text{completion time} \\
    & f_i :& \text{FIFO use } 0 \leq f_i \leq 1 \\
    & \textrm{II} :& \text{iteration interval} \frac{\# instructions}{dispatches/cycle} \\
\end{align*}

\begin{align}
    \color{lightblue}{\text{Hard Constraints }} \qquad & \forall i,j \cdot i \rightarrow j \qquad t_i + \epsilon \leq t_j  \\
								 & 0 \leq t_i \leq b_i \leq \#\text{stages} \cdot \textrm{II}  \\
								 & b_i + \epsilon \leq t_i + \textrm{II} \\
    \color{lightblue}{\text{Objective Function }} \qquad   & \text{min} \sum_{i} (b_i - t_i + f_i) + \text{Penalties}
\end{align}

*Key Idea:* Encode choice heuristics as penalties, adjust preference
between heuristics by scaling
*** TODO COMMENT update optimization model from beamer
** IO Penalty
   - *IDEA* penalize dispatch time of instructions based on the quantity and
    latencies of it's dependencies
   - *Note* This is a *penalty* not a *hard* constraint on latencies
   \begin{align*}
            \color{lightblue}{\text{Given }} \qquad  & t_i,t_j \qquad & \forall i,j \mid i \rightarrow j  \\
            \color{lightblue}{\text{For each i }} \qquad & N_j  =  \sum_{i \rightarrow j} \text{latency}(j) & \\
            \qquad & \qquad & \qquad \\
            \qquad & \mathbb{IO}(i) = \sum_{j} \frac{1}{N_j} \mathbb{IN}(t_i - t_j) & \qquad 
    \end{align*}
*** TODO COMMENT update IO penalty from beamer
** Stochastic Scaling
   - The scaling $\frac{1}{N_j}$ may be a good *guess*, but not necessarily effective in practice
   - *IDEA* scale the *IO penalty* stochastically
   \begin{align*}
    \color{lightblue}{\text{Define a Clustering}} \qquad & \mathbb{C} = \text{Cluster}(\forall i \mid i \rightarrow j) \\
    \color{lightblue}{\text{For each Cluster i}} \qquad & c_i \in \mathbb{RAND(R)} \\
    \color{lightblue}{\text{Stochastic Penalty}} \qquad & \sum_i c_i \cdot \mathbb{IO}(i)
   \end{align*}
*** TODO COMMENT update stochastic scaling from beamer
** Topology Analysis
      *Assertion* For each scaling $\color{lightgreen}{c_i \in \mathbb{RAND(R)}}$, there exists an $\color{lightgreen}{\epsilon \in
     \mathbb(R)}$ such that $\color{lightgreen}{c_i + \epsilon}$
   produces a distinct schedule from $\color{lightgreen}{c_i}$
   - If the assertion fails, the clustering is useless (possible to avoid such
     clusterings?)
   - What does this topology look like?
   - Do all valid schedules span this topology?
   - Prove stochastic scaling spans the topology of all schedules
   - Use PCA analysis to select useful pull parameters
   - Develop clustering methods for assigning pull parameters
*** TODO COMMENT update topology analysis from beamer
* Timeline
** TODO COMMENT Timeline

* Bib                                                                :ignore:
# LaTeX: \addcontentsline{toc}{section}{References}
#+LaTeX: \addcontentsline{toc}{part}{References}
#+LaTeX: \printbibliography

* Org-Bibtex                                                         :ignore:
** COMMENT PUT BIBTEX ENTRIES HERE IN SUBSECTION ENDED WITH IGNORE USING ORG-BIBTEX-YANK COMMAND :ignore:
** COMMENT EXPORT TO References.bib USING ORG-BIBTEX COMMAND :ignore:
** Postpass code optimization of pipeline constraints :ignore:
   :PROPERTIES:
   :TITLE:    Postpass code optimization of pipeline constraints
   :BTYPE:    article
   :CUSTOM_ID: hennessy1983postpass
   :AUTHOR:   Hennessy, John and Gross, Thomas
   :JOURNAL:  ACM Trans. Program. Lang. Syst.;(United States)
   :VOLUME:   3
   :YEAR:     1983
   :PUBLISHER: Stanford Univ., CA
   :END:
** Constraint-Based Register Allocation and Instruction Scheduling   :ignore:
   :PROPERTIES:
   :TITLE:    Constraint-Based Register Allocation and Instruction Scheduling
   :BTYPE:    phdthesis
   :CUSTOM_ID: castaneda2018constraint
   :AUTHOR:   Casta{\~n}eda Lozano, Roberto
   :YEAR:     2018
   :SCHOOL:   KTH Royal Institute of Technology
   :END:
*** COMMENT [[http://www.diva-portal.org/smash/get/diva2:1232941/FULLTEXT01.pdf][Constraint Based Register allocation and Instruction Scheduling]]   
** Combining register allocation and instruction scheduling  :ignore:
  :PROPERTIES:
  :TITLE:    Combining register allocation and instruction scheduling
  :BTYPE:    article
  :CUSTOM_ID: motwani1995combining
  :AUTHOR:   Motwani, Rajeev and Palem, Krishna V and Sarkar, Vivek and Reyen, Salem
  :JOURNAL:  Courant Institute, New York University
  :YEAR:     1995
  :END:
*** COMMENT [[https://arxiv.org/pdf/1804.02452.pdf][Combining Register Allocation and Instruction Scheduling]]

** Register Allocation with Instruction Scheduling :ignore:
   :PROPERTIES:
   :TITLE:    Register Allocation with Instruction Scheduling
   :BTYPE:    article
   :CUSTOM_ID: Pinter:1993:RAI:173262.155114
   :AUTHOR:   Pinter, Shlomit S.
   :JOURNAL:  SIGPLAN Not.
   :ISSUE_DATE: June 1993
   :VOLUME:   28
   :NUMBER:   6
   :MONTH:    jun
   :YEAR:     1993
   :ISSN:     0362-1340
   :PAGES:    248--257
   :NUMPAGES: 10
   :URL:      http://doi.acm.org/10.1145/173262.155114
   :DOI:      10.1145/173262.155114
   :ACMID:    155114
   :PUBLISHER: ACM
   :ADDRESS:  New York, NY, USA
   :END:
*** COMMENT [[http://delivery.acm.org/10.1145/160000/155114/p248-pinter.pdf?ip=130.113.109.215&id=155114&acc=ACTIVE%20SERVICE&key=FD0067F557510FFB%2ED816932E3DB0B89D%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1564584969_261ecbe26f943fdf33018f2f39ebfbd2][Register Allocation with Instruction Scheduling: A New Approach]]

** Evaluating the use of register queues in software pipelined loops :ignore:
   :PROPERTIES:
   :TITLE:    Evaluating the use of register queues in software pipelined loops
   :BTYPE:    article
   :CUSTOM_ID: tyson2001evaluating
   :AUTHOR:   Tyson, Gary S and Smelyanskiy, Mikhail and Davidson, Edward S
   :JOURNAL:  IEEE Transactions on Computers
   :VOLUME:   50
   :NUMBER:   8
   :PAGES:    769--783
   :YEAR:     2001
   :PUBLISHER: IEEE
   :END:
*** COMMENT [[https://ieeexplore.ieee.org/document/947006][Evaluating the Use of Register Queues in Software Pipelined Loops]]

** Software-pipelining on multi-core architectures :ignore:
   :PROPERTIES:
   :TITLE:    Software-pipelining on multi-core architectures
   :BTYPE:    inproceedings
   :CUSTOM_ID: douillet2007software
   :AUTHOR:   Douillet, Alban and Gao, Guang R
   :BOOKTITLE: Proceedings of the 16th International Conference on Parallel Architecture and Compilation Techniques
   :PAGES:    39--48
   :YEAR:     2007
   :ORGANIZATION: IEEE Computer Society
   :END:
*** COMMENT [[https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4336198][Software Pipelining on Multi-core Architectures]]

** Global instruction scheduling for superscalar machines :ignore:
   :PROPERTIES:
   :TITLE:    Global instruction scheduling for superscalar machines
   :BTYPE:    inproceedings
   :CUSTOM_ID: bernstein1991global
   :AUTHOR:   Bernstein, David and Rodeh, Michael
   :BOOKTITLE: ACM SIGPLAN Notices
   :VOLUME:   26
   :NUMBER:   6
   :PAGES:    241--255
   :YEAR:     1991
   :ORGANIZATION: ACM
   :END:
*** COMMENT [[http://pages.cs.wisc.edu/~fischer/cs701.f06/berstein_rodeh.pdf][Global instruction scheduling for superscalar machines]]

** Efficient instruction scheduling for a pipelined architecture :ignore:
   :PROPERTIES:
   :TITLE:    Efficient instruction scheduling for a pipelined architecture
   :BTYPE:    inproceedings
   :CUSTOM_ID: gibbons1986efficient
   :AUTHOR:   Gibbons, Philip B and Muchnick, Steven S
   :BOOKTITLE: Acm sigplan notices
   :VOLUME:   21
   :NUMBER:   7
   :PAGES:    11--16
   :YEAR:     1986
   :ORGANIZATION: ACM
   :END:
*** COMMENT [[http://delivery.acm.org.libaccess.lib.mcmaster.ca/10.1145/20000/13312/p11-gibbons.pdf?ip=130.113.111.210&id=13312&acc=ACTIVE%20SERVICE&key=FD0067F557510FFB%2ED816932E3DB0B89D%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1566799515_cd89aab9c480dc291845f8e0ab01483f][Efficient scheduling for pipelined architectures]]
** Instruction-level parallel processing: history, overview, and perspective :ignore:
   :PROPERTIES:
   :TITLE:    Instruction-level parallel processing: history, overview, and perspective
   :BTYPE:    incollection
   :CUSTOM_ID: rau1993instruction
   :AUTHOR:   Rau, B Ramakrishna and Fisher, Joseph A
   :BOOKTITLE: Instruction-Level Parallelism
   :PAGES:    9--50
   :YEAR:     1993
   :PUBLISHER: Springer
   :END:
*** COMMENT [[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.799.7976&rep=rep1&type=pdf][Instruction-level parallel processing]]
** Register Allocation \& Spilling via Graph Coloring :ignore:
   :PROPERTIES:
   :TITLE:    Register Allocation \& Spilling via Graph Coloring
   :BTYPE:    article
   :CUSTOM_ID: Chaitin:1982:RAS:872726.806984
   :AUTHOR:   Chaitin, G. J.
   :JOURNAL:  SIGPLAN Not.
   :ISSUE_DATE: June 1982
   :VOLUME:   17
   :NUMBER:   6
   :MONTH:    jun
   :YEAR:     1982
   :ISSN:     0362-1340
   :PAGES:    98--101
   :NUMPAGES: 4
   :URL:      http://doi.acm.org.libaccess.lib.mcmaster.ca/10.1145/872726.806984
   :DOI:      10.1145/872726.806984
   :ACMID:    806984
   :PUBLISHER: ACM
   :ADDRESS:  New York, NY, USA
   :END:
*** COMMENT [[http://delivery.acm.org.libaccess.lib.mcmaster.ca/10.1145/810000/806984/p98-chaitin.pdf?ip=130.113.111.210&id=806984&acc=ACTIVE%20SERVICE&key=FD0067F557510FFB%2ED816932E3DB0B89D%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1566800641_adc76422d7bd921a1521c82893f6dceb][Register Allocation]]

** Optimal basic block instruction scheduling for multiple-issue processors using constraint programming :ignore:
  :PROPERTIES:
  :TITLE:    Optimal basic block instruction scheduling for multiple-issue processors using constraint programming
  :BTYPE:    article
  :CUSTOM_ID: malik2008optimal
  :AUTHOR:   Malik, Abid M and McInnes, Jim and Van Beek, Peter
  :JOURNAL:  International Journal on Artificial Intelligence Tools
  :VOLUME:   17
  :NUMBER:   01
  :PAGES:    37--54
  :YEAR:     2008
  :PUBLISHER: World Scientific
  :END:
*** COMMENT [[https://cs.uwaterloo.ca/research/tr/2005/CS-2005-19.pdf][Optimal Basic Block Instruction Scheduling for Multiple Issue Processors Using Constraint Programming]] (IBM guys)

** MultiLoop: Efficient Software Pipelining for Modern Hardware :ignore:
   :PROPERTIES:
   :TITLE:    MultiLoop: Efficient Software Pipelining for Modern Hardware
   :BTYPE:    inproceedings
   :CUSTOM_ID: Anand:2007:MES:1321211.1321242
   :AUTHOR:   Anand, Christopher Kumar and Kahl, Wolfram
   :BOOKTITLE: Proceedings of the 2007 Conference of the Center for Advanced Studies on Collaborative Research
   :SERIES:   CASCON '07
   :YEAR:     2007
   :LOCATION: Richmond Hill, Ontario, Canada
   :PAGES:    260--263
   :NUMPAGES: 4
   :URL:      http://dx.doi.org/10.1145/1321211.1321242
   :DOI:      10.1145/1321211.1321242
   :ACMID:    1321242
   :PUBLISHER: IBM Corp.
   :ADDRESS:  Riverton, NJ, USA
   :END:
*** COMMENT [[https://link.springer.com/content/pdf/10.1007%2F978-1-4899-7797-7_6.pdf][Multi-Loop: Efficient Software Piplining for Modern Hardware]] (Anand,Kahl)

** Stochastic Program Optimization :ignore:
   :PROPERTIES:
   :TITLE:    Stochastic Program Optimization
   :BTYPE:    article
   :CUSTOM_ID: Schkufza:2016:SPO:2886013.2863701
   :AUTHOR:   Schkufza, Eric and Sharma, Rahul and Aiken, Alex
   :JOURNAL:  Commun. ACM
   :ISSUE_DATE: February 2016
   :VOLUME:   59
   :NUMBER:   2
   :MONTH:    jan
   :YEAR:     2016
   :ISSN:     0001-0782
   :PAGES:    114--122
   :NUMPAGES: 9
   :URL:      http://doi.acm.org/10.1145/2863701
   :DOI:      10.1145/2863701
   :ACMID:    2863701
   :PUBLISHER: ACM
   :ADDRESS:  New York, NY, USA
   :END:
*** COMMENT [[http://delivery.acm.org/10.1145/2870000/2863701/p114-schkufza.pdf?ip=130.113.109.215&id=2863701&acc=ACTIVE%20SERVICE&key=FD0067F557510FFB%2ED816932E3DB0B89D%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1564586602_105c24f842dcdd9a6b420b8bd3191e66][Stochastic Program Optimization]]

** Kristons Thesis  :ignore:
*** COMMENT [[https://macsphere.mcmaster.ca/bitstream/11375/18865/2/costa_kriston_p_201602_msc.pdf][Approximation Algorithm based Approach Instruction Scheduling]] (Kriston's thesis)
* COMMENT footer                                                     :ignore:

# Local Variables:
# eval: (progn (org-babel-goto-named-src-block "make-reports-class") (org-babel-execute-src-block) (outline-hide-sublevels 1))
# compile-command: (progn (org-babel-tangle) (org-latex-export-to-pdf) (async-shell-command "evince proposal.pdf"))
# End:
