#+Title: Ph.D Committee Meeting
#+DATE: 2019-11-22
#+EMAIL: curtis.dalves@gmail.com
#+AUTHOR: Curtis D'Alves

* Completed Degrees 
  Honours B.Sc Computer Science (2014), M.Sc. Computer Science (2016)
 In progress: Ph.D Engineering (Computer Science)

* Courses taken during Ph.D Engineering (Started Fall 2017) 
  (Comprehensive Part1 Completed 2017/05/26, Part 2 Completed 2020/01/06)
  CAS 781 (Adv Top CAS) A+
  CAS 705 (Computability and Complexity) B+
  STATS 780 (Data Science) A
  CAS 750 Pending 
  
* Thesis Related Work Experience 
  IBM CAS Project 1006 - Exploring Stochastic Algorithms for Instruction Scheduling  (2017-present)
 
* Progress Since Last Meeting (2019/11/22) 

 * Work on COCONUT (development environment needed for thesis research)
  - Broke code base up into hyper-graph library (back-end) and code generation
    library (front-end)
  - Optimized hyper-graph library to support more efficient graph operations
  - Integrated Hashed Expression with code gen library
  - Updated Hashed Expression library to support operations needed for stochastic
    scheduling optimization
   
 * Co-Author Contributions Paper 
  "Designing and evaluating new instructions that accelerate sigmoid-based machine 
  learning" in publication "CASCON '20:
  Proceedings of the 30th Annual International Conference on Computer Science
  and Software EngineeringNovember 2020 Pages 189–197"

 * Presentations
   - Presented Hashed Expression at CASCON '20
   - Presented paper "Designing and evaluating new instructions that accelerate
     sigmoid-based machine learning" at CASCON '20

* Planned Thesis contributions
  My thesis will explore the use of stochastic algorithms for instruction
  scheduling (notable work done in this area by Eric Schkufza, Rahul Sharma, and
  Alex Aiken. “Stochastic Program Optimization”) and using generated schedules
  to develop hyper-heuristics for scheduling (some work on using
  hyper-heuristics in instruction scheduling done by Mark Stephenson et al.
  “Genetic programming applied to compiler heuristic optimization” and Ricardo
  Nabinger Sanchez et al. “Using machines to learn method-specific compilation
  strategies”). If successful my research will provide not only a novel method
  for training these hyper-heuristics via stochastic-ally generated schedules,
  but also a means to perform analysis on the effectiveness of different
  compiler heuristics.
** Benchmarking
  I am using IBM's MASS libraries as a testing bed, and will benchmark newly
  generated schedules against previous iterations of the libraries release
  (which have been scheduling both by hand and using a different stochastic
  scheduling algorithm). So far I've achieved up to a 20% speedup on core MASS
  library functions. To help generate these schedules, I've been actively
  developing and maintaining a code generation library (known as COCONUT) and
  optimization library (known as Hashed Expression).

* Timeline (Since Last Meeting)
  - Refactor COCONUT library (Completed)
  - Integrate Hashed Expression with COCONUT (Completed)
  - Present Hashed Expression at CASCON (Completed)
  - Generate schedules for MASS POWER (Jan 2021)
  - Write paper on schedule optimization for OoO architectures and submit to
    TACO (Feb 2021)
  - Experiment with training hyper-heuristics (Jan-Apr 2021)
  - Write paper on Hyper Heuristics to submit to one of the big ML conferences:
    ICML,IJCAL,etc (May 2021)
  - Attempt to apply Hyper-Heuristic methods to schedule for Z (Jun 2021)
  - Defend Thesis (July 2021)
  
  
  
