* Header :ignore:
# -*- mode: org; -*-

#+REVEAL_ROOT: https://cdn.jsdelivr.net/reveal.js/3.0.0/
#+REVEAL_THEME: league

#+OPTIONS: reveal_title_slide:auto num:nil toc:nil timestamp:nil

#+MACRO: color @@html:<font color="$1">$2</font>@@
#+MACRO: alert @@html:<font color="lightblue">$1</font>@@

#+REVEAL_EXTRA_CSS: ./mystyle.css
# #+REVEAL_EXTRA_CSS: /Users/curtis/reveal.js/css/theme/night.css

# To load Org-reveal, type “M-x load-library”, then type “ox-reveal”.


#+Title: Ph.d Proposal
#+Date: 2019-08-08
#+Email: curtis.dalves@gmail.com
#+Author: Curtis D'Alves

* Instruction Scheduling Intro

** Instruction Scheduling
  - Given a set of instructions and dependencies, designate an order 
    (find a {{{alert(schedule)}}}) satisfying the dependencies and optimizing performance
  - Known NP-Complete 
    Practically solved by
    - {{{alert(Heuristics)}}}
    - {{{alert(Approximation Algorithms)}}}

** COMMENT Testing
   #+REVEAL_HTML: <div class="column" style="float:left; width: 50%">
   - Define Clustering
   - For Each Cluster i
   - Stochastic Penalty
   #+REVEAL_HTML: </div>
   #+REVEAL_HTML: <div class="column" style="float:right; width: 50%">
   - $ x + 5 $
   #+REVEAL_HTML: </div>
** Types of Scheduling Algorithms
   - {{{alert(Basic Block:)}}} break code into blocks within branches (most commonly performed scheduling)
	 - {{{alert(Global Scheduling:)}}} schedule across basic block boundaries
	 - {{{alert(Modulo Scheduling:)}}} schedules basic blocks inside of a loop, seeking to
     optimize by interleaving iterations
	 - {{{alert(Trace Scheduling:)}}} tries to optimize control flow by predicting routes
     taken on branches

** Register Allocation
   - Given a schedule, assign registers keeping in mind
    - limited number of registers
    - can't rewrite a register until consumed by dependent instructions
   - Known NP-Complete
     - Practically solved using non-optimal {{{alert(Graph Coloring)}}} algorithms
     - done seperately from instruction scheduling (before or afterwords)
** Graph Colouring
   [[file:figures/nshape.png]]
   
   Find a {{{alert(k-Colouring)}}} for the dependency graph, where *$k = \#Registers$*

** Spilling
   - What if a {{{alert(k-Coloring)}}} can't be found? Must {{{alert(Spill)}}} memory
	 - Simply insert new {{{alert(Load / Store)}}} instructions as needed
   - Potentially {{{alert(creates new stalls)}}} in the pipeline, need to re-perform
     scheduling
   - May use up dispatch slots
   - An {{{alert(Ideal Schedule)}}} has no spilling
 
** Combining Register Allocation and Instruciton Scheduling
   - Register Allocation is generally done after instruction scheduling
   - This can {{{alert(make spilling necessary)}}}
   - Register allocation can be performed before instruction schedule, but will
     {{{alert(constrain the space of valid schedules)}}}
   - Attempts to {{{alert(combine register allocation and scheduling)}}} are
     rare and yield an {{{alert(NP-hard)}}} problem cite:motwani1995combining cite:Pinter:1993:RAI:173262.155114

* Instruction Pipelining
** Classic RISC Pipeline
  [[file:figures/pipeline.png]]
  
 Simple example pipeline with no stalls and a single instruction fetch per
 "cycle"

** SuperScalar Pipelining
   #+ATTR_HTML: :width 50% :height 50%
   [[file:figures/superscaler.png]]
   
   Superscalar architectures can fetch multiple instructions per "cycle" and
   require more thought about resource restriction (such as limits on ALU's)

** Pipeline Stalls
   [[file:figures/bubbles.png]]
   [[file:figures/bubbles2.png]]
   
   An {{{alert(Ideal Schedule)}}} (like in the previous figures) contains *NO* stalls (often
   not possible)

** Hazards
		- {{{alert(Data Hazards)}}}
			- read after write {{{alert(RAW)}}}
			- write after read {{{alert(WAR)}}}
			- write after write {{{alert(WAW))}}}
		- {{{alert(Structural Hazards)}}} occurs when an aspect of hardware is accessed at the same time
		- {{{alert(Control Hazards)}}} caused by branching, next instruction unknown
    Hardware encountering hazards causees stalls in the pipeline

** Staging : Example 3 Staged Loop
   #+ATTR_HTML: :width 50% :height 50%
   [[file:figures/staging.png]]

   When performing {{{alert(modulo scheduling)}}}, a basic block of a loop can be broken
   into stages and the loop can be {{{alert(unrolled)}}} to interleave stages between
   iterations

** Iteration Interval
   #+BEGIN_cmath 
   $$ \frac{\text{latency height}}{\# \text{stages}} \leq \textrm{II} $$
   #+END_cmath
   - the maximum {{{alert(number of cyles)}}} to complete a loop iteration
   - exact number is complicated {{{alert(Out of Order Execution)}}} / {{{alert(Staging)}}}
*** TODO COMMENT finish II explanation

** Register Remapping
   When executing machine code, hardware maps {{{alert(Logical Registers)}}} to {{{alert(Physical Registers)}}}
   -  {{{alert(Logical Registers)}}} are a set of registers usable directly when
     writing/generating assembly code (limited by system architecture)
   - {{{alert(Physical Registers)}}} are a set of registers actually available in hardware
   Having a larger number of Physical registers than Logical registers gives
   hardware extra flexibility when dispatching instructions for {{{alert(Out of Order Execution)}}}

** Out-Of-Order Dispatcher Example
   #+BEGIN_SRC ditaa :file figures/hello-world.png
   /--------------\      /-------------\
   | Instr 0.     | ...  | Instr. n    |
   \--------------/      \-------------/
         |           |         |
   /--------------\      /-------------\
   | Fetcher 0.   | ...  | Fetcher n   |
   \--------------/      \-------------/
         |           |         |
         |           |         |
         \---------------------/
                     |
                     v
            /-----------------\
            | cBLU Grouper    |           Register Remapping
            \-----------------/
                     |
                     |
                     v 
            /-----------------\
            | cBLU Dispather  |
            \-----------------/
                     |
     -------------------------------------
     |      |                     |      |
   /----\ /----\               /----\ /----\
   |cRED| |cRED|     ....      |cRED| |cRED|    OoO Exection
   \----/ \----/               \----/ \----/
     |      |                     |      |
     -------------------------------------
                     |
                     v 
            /-----------------\
            | cBLU Retire     |           Register UnMapping
            \-----------------/
   #+END_SRC

   #+ATTR_HTML: :width 50% :height 50%
   #+RESULTS:
   [[file:figures/hello-world.png]]

** Register Pressure In Staged Loops
   - Staging can {{{alert(increase pipeline throughput)}}} by enabling more instructions to
     be scheduled between high latency operations and subsequent use
   - However this also increases the number of {{{alert(live instances of loop
     variables)}}} and thus requires more registers to accommodate the schedule
   - To deal with the access number of registers required that may not be
     available, {{{alert(Register Queuing)}}} (what we term FIFO's) may be
     necessary
   - Existing works have explored schemes of register queuing such as
     {{{alert(Modulo Variable Expansion)}}} and {{{alert(Rotating Register
     File)}}} cite:tyson2001evaluating
* Previous Works
** List Scheduling (most commonly performed scheduling)
   	Simple heuristic.  Choose a prioritized topological order that
    - Respects the edges in the data-dependence graph (*topological*)
    - Heuristic choice among options, e.g pick first the node with the longest path extending from that node *prioritized*
    Most commonly used method for scheduling. Efficient but yields far less than
    optimal schedules

** Issues with List Scheduling
    - Many factors to consider when constructing a schedule (everything listed in this presentation and more!)    
    - Difficult (or more accurately impossible!) to consider all these aspects into a single choice heuristic        
    - Combinations of heuristics can be used, and multiple iterations performed,
      but each will usually undo the work of the other

* Previous Works Constraint Programming
** Optimial Basic Block Instruction Scheduling With Constraint Programming
   cite:malik2008optimal  Found provably optimal schedules for basic blocks using constraint
     programming, using the following types of constraints
   - {{{alert(Latency Constraints)}}}, i.e
     - Given a labeled dependency DAG $G = (N,E)$ 
       - $\forall (i,j) \in E \cdot j \geq i + l(i,j)$ 
   - {{{alert(Resource Constraints)}}} that ensured functinonal units were not exceded
   - {{{alert(Distance Contstraints)}}}, i.e
     - Given a labeled dependency *DAG*  $G = (N,E)$ 
        - $\forall (i,j) \in E \cdot j \geq i + d(i,j)$

** Optimial Basic Block Instruction Scheduling With Constraint Programming (Limitations)
   The hard constraints on latency would not account for {{{alert(Register Remapping)}}} in
   {{{alert(Out Of Order Execution)}}} that would be able to find more optimal schedules
   despite the fact that latencies in normal execution would create {{{alert(pipeline stalls)}}}
   #+begin_example
   fma r3,r3,r4
   fma r2,r2,r4
   fma r1,r1,r4
   fma r0,r0,r4
   #+end_example
   On a system with only 5 registers and an instruction fma of large enough
   latency, the scheduler would push these instructions apart. However a machine
   could use register remapping to execute these instructions efficiently *OoO*
   making that constraint unnecessary

* Previous Works Program Optimization Through Stochastic Search
** Program Optimization through Stochastic Search
   cite:Schkufza:2016:SPO:2886013.2863701
  - Suitable for {{{alert(Short Basic Block)}}} assembly code sequences
  - Utilizes a multiple pass {{{alert(Stochastic Algorithm)}}}
  - Encodes constraints as a {{{alert(Cost Function)}}} and uses a
    {{{alert(Markov Chain Monte Carlo Sampler)}}} to explore space of all
    possible schedules

** Program Optimization through Stochastic Search
   Each pass of the optimization minimizes the cost function
#+BEGIN_cmath
  \begin{equation*}
    cost(R; T) = w_e \times eq(R; T) + w_p \times perf(R; T)
  \end{equation*}
#+END_cmath
  | $\color{lightgreen}{\boldsymbol{R}}$   | any rewrite of the program                                        |
  | $\color{lightgreen}{\boldsymbol{T}}$   | the input program sequence                                        |
  | $\color{lightgreen}{eq(\cdot)}$        | the equivalence function (0 if $\color{lightgreen}{R \equiv T}$ ) |
  | $\color{lightgreen}{perf(\cdot)}$      | a metric for performance                                          |
  | $\color{lightgreen}{\boldsymbol{w_e}}$ | weight for the equivalence term                                   |
  | $\color{lightgreen}{\boldsymbol{w_p}}$ | weight for the performance term                                   |

** Program Optimization through Stochastic Search (Limitations)
   - Only optimizes basic blocks ({{{alert(no loops)}}})
   - Extremely innefficent (only practical for very short scheduling)
   - Performed in multiple passes with model checking
   - Cost function doesn't model the space of valid checking (hence model
     checking is required per each rewrite)

* Proposed Research

** Constrained Optimization Model For Modulo Scheduling

#+BEGIN_cmath
#+HTML: <small>
\begin{align*}
    \color{lightblue}{\text{Objective Variables }} & t_i, b_i, f_i:& \mathbb{R} \\
    \color{lightblue}{\text{Constants }} & \textrm{II} :& \mathbb{R} \\
    \color{lightblue}{\text{Indicator Function }} & \mathbb{IN} :& \mathbb{R} \rightarrow \mathbb{R} \\
    & t_i :& \text{dispatch time} \\
    & b_i :& \text{completion time} \\
    & f_i :& \text{FIFO use } 0 \leq f_i \leq 1 \\
    & \textrm{II} :& \text{iteration interval} \frac{\# instructions}{dispatches/cycle} \\
\end{align*}
#+HTML: </small>
#+END_cmath

** Constrained Optimization Model
#+BEGIN_cmath
#+HTML: <small>
\begin{align}
    \color{lightblue}{\text{Hard Constraints }} \qquad & \forall i,j \cdot i \rightarrow j \qquad t_i + \epsilon \leq t_j  \\
								 & 0 \leq t_i \leq b_i \leq \#\text{stages} \cdot \textrm{II}  \\
								 & b_i + \epsilon \leq t_i + \textrm{II} \\
    \color{lightblue}{\text{Objective Function }} \qquad   & \text{min} \sum_{i} (b_i - t_i + f_i) + \text{Penalties}
\end{align}
#+HTML: </small>    
#+END_cmath

{{{alert(Key Idea:)}}} Encode choice heuristics as penalties, adjust preference
between heuristics by scaling

** IO Penalty
   - {{{alert(IDEA)}}} penalize dispatch time of instructions based on the quantity and
    latencies of it's dependencies
   - {{{alert(Note)}}} This is a *penalty* not a *hard* constraint on latencies

#+BEGIN_cmath
#+HTML: <small>
   \begin{align*}
            \color{lightblue}{\text{Given }} \qquad  & t_i,t_j \qquad & \forall i,j \mid i \rightarrow j  \\
            \color{lightblue}{\text{For each i }} \qquad & N_j  =  \sum_{i \rightarrow j} \text{latency}(j) & \\
            \qquad & \qquad & \qquad \\
            \qquad & \mathbb{IO}(i) = \sum_{j} \frac{1}{N_j} \mathbb{IN}(t_i - t_j) & \qquad 
    \end{align*}
#+HTML: </small>
#+END_cmath

** Stochastic Scaling
   - The scaling $\color{lightgreen}{\frac{1}{N_j}}$ may be a good *guess*, but not necessarily effective in practice
   - {{{alert(IDEA)}}} scale the {{{alert(IO penalty)}}} stochastically
#+BEGIN_cmath
#+HTML: <small>
      \begin{align*}
          \color{lightblue}{\text{Define a Clustering}} \qquad & \mathbb{C} = \text{Cluster}(\forall i \mid i \rightarrow j) \\
          \color{lightblue}{\text{For each Cluster i}} \qquad & c_i \in \mathbb{RAND(R)} \\
          \color{lightblue}{\text{Stochastic Penalty}} \qquad & \sum_i c_i \cdot \mathbb{IO}(i)
        \end{align*}
#+HTML: </small>
#+END_cmath

** Schedule Topology
   {{{alert(Assertion)}}} For each scaling $\color{lightgreen}{c_i \in \mathbb{RAND(R)}}$, there exists an $\color{lightgreen}{\epsilon \in
     \mathbb(R)}$ such that $\color{lightgreen}{c_i + \epsilon}$
   produces a distinct schedule from $\color{lightgreen}{c_i}$
   - If the assertion fails, the clustering is useless (possible to avoid such
     clusterings?)
   - What does this topology look like?
   - Do all valid schedules span this topology?

** Topology Analysis
   - Prove stochastic scaling spans the topology of all schedules
   - Use PCA analysis to select useful pull parameters
   - Develop clustering methods for assigning pull parameters

* References
  bibliographystyle:alphadin
  bibliography:References.bib
